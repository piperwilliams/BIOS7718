{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_unet import image_util, unet, util\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary annotation masks of each of the four channels \n",
    "filenames = sorted(glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataRaw/annotation_matfiles/*.mat'))\n",
    "\n",
    "for f in filenames:\n",
    "    mat_file = scipy.io.loadmat(f)\n",
    "    labs = mat_file['Labels'].reshape(1,-1,1)\n",
    "    pos = np.dstack(mat_file['Positions'])\n",
    "\n",
    "    # data frame with label and position info\n",
    "    mat = np.concatenate((labs, pos), axis = -1)\n",
    "    mat_labs = np.uint16(mat[:,:,0]).reshape(-1,1)\n",
    "    mat_x = np.uint16(mat[:,:,1]).reshape(-1,1)\n",
    "    mat_x = mat_x - 1 # to match index of array\n",
    "    mat_y = np.uint16(mat[:,:,2]).reshape(-1,1)\n",
    "    mat_y = mat_y - 1 # to match index of array\n",
    "    mat = pd.DataFrame(data=np.column_stack((mat_labs, mat_x, mat_y)), \n",
    "                       columns=['Labels','X','Y'])\n",
    "\n",
    "    # separate based on label\n",
    "    mat_1 = mat.loc[mat['Labels'] == 1]\n",
    "    mat_2 = mat.loc[mat['Labels'] == 2]\n",
    "    mat_3 = mat.loc[mat['Labels'] == 3]\n",
    "    mat_4 = mat.loc[mat['Labels'] == 4]\n",
    "    \n",
    "    if f[90:96] == 'img091':\n",
    "        mat_2.set_value(10, 'Y', 0)\n",
    "        mat_2.set_value(98, 'Y', 0)\n",
    "    \n",
    "    zero_1 = np.zeros([500,500])\n",
    "    zero_2 = np.zeros([500,500])\n",
    "    zero_3 = np.zeros([500,500])\n",
    "    zero_4 = np.zeros([500,500])\n",
    "\n",
    "    # generate annotations\n",
    "    zero_1[mat_1['Y'], mat_1['X']] = 255\n",
    "    zero_2[mat_2['Y'], mat_2['X']] = 255\n",
    "    zero_3[mat_3['Y'], mat_3['X']] = 255\n",
    "    zero_4[mat_4['Y'], mat_4['X']] = 255\n",
    "    \n",
    "    base_name, ext = os.path.splitext(f)\n",
    "    \n",
    "    np.save(base_name[0:62] + 'DataProcessed/numpy_mask/' + \n",
    "            base_name[90:96] + '_1', zero_1)\n",
    "    np.save(base_name[0:62] + 'DataProcessed/numpy_mask/' + \n",
    "            base_name[90:96] + '_2', zero_2)\n",
    "    np.save(base_name[0:62] + 'DataProcessed/numpy_mask/' + \n",
    "            base_name[90:96] + '_3', zero_3)\n",
    "    np.save(base_name[0:62] + 'DataProcessed/numpy_mask/' + \n",
    "            base_name[90:96] + '_4', zero_4)\n",
    "    \n",
    "    cv2.imwrite(base_name[0:62] + 'DataProcessed/binary_mask_final/' + \n",
    "                base_name[90:96] + '_1.png', zero_1)\n",
    "    cv2.imwrite(base_name[0:62] + 'DataProcessed/binary_mask_final/' + \n",
    "                base_name[90:96] + '_2.png', zero_2)\n",
    "    cv2.imwrite(base_name[0:62] + 'DataProcessed/binary_mask_final/' + \n",
    "                base_name[90:96] + '_3.png', zero_3)\n",
    "    cv2.imwrite(base_name[0:62] + 'DataProcessed/binary_mask_final/' + \n",
    "                base_name[90:96] + '_4.png', zero_4)\n",
    "\n",
    "# for image091, there are 2 Y coordinates greater than 500 \n",
    "# (equals 65535, should be 0, indexes = 10 and 98)\n",
    "# commands I need to use to fix after creating data frame (img091 only):\n",
    "#    mat.set_value(10, 'Y', 0)\n",
    "#    mat.set_value(98, 'Y', 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilate the annotation masks\n",
    "filenames = sorted(glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/binary_mask_final/*.png'))\n",
    "\n",
    "for f in filenames:\n",
    "    img = cv2.imread(f, 0)\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    dilate = cv2.dilate(img, kernel, iterations = 1)\n",
    "    base_name, ext = os.path.splitext(f)\n",
    "    np.save(base_name[0:62] + 'DataProcessed/dilate_numpy_mask/' + \n",
    "            base_name[94:] + '_mask', dilate)\n",
    "    cv2.imwrite(base_name[0:62] + 'DataProcessed/dilate_mask_final/' + \n",
    "                base_name[94:] + '_mask.png', dilate)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate multi-class annotation masks\n",
    "filenames = sorted(glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/dilate_mask_final/*.png'))\n",
    "\n",
    "for f in filenames:\n",
    "    mask_1 = cv2.imread(f[0:101] + '1_mask.png',0)\n",
    "    mask_2 = cv2.imread(f[0:101] + '2_mask.png',0)\n",
    "    mask_3 = cv2.imread(f[0:101] + '3_mask.png',0)\n",
    "    mask_4 = cv2.imread(f[0:101] + '4_mask.png',0)\n",
    "    \n",
    "    mask_merge = np.maximum.reduce([mask_1, mask_2, mask_3, mask_4])\n",
    "    mask_merge_final = ~mask_merge\n",
    "    mask_stack = np.dstack((mask_1, mask_2, mask_3, mask_4, mask_merge_final))\n",
    "    \n",
    "    np.save(f[0:76] + 'dilate_numpy_merge/' + \n",
    "            f[94:101] + 'mask', mask_stack)\n",
    "    cv2.imwrite(f[0:76] + 'dilate_merge_final/' + \n",
    "                f[94:101] + 'mask.png', mask_merge)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate black and white images from RGB images\n",
    "filenames = sorted(glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataRaw/image_data/*.png'))\n",
    "\n",
    "for f in filenames:\n",
    "    img = cv2.imread(f)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(f[0:70] + 'image_data_gray/' + f[81:], img_gray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate randomly cropped and rotated images\n",
    "def randomCrop(img, mask, width, height):\n",
    "    assert img.shape[0] >= height\n",
    "    assert img.shape[1] >= width\n",
    "    assert img.shape[0] == mask.shape[0]\n",
    "    assert img.shape[1] == mask.shape[1]\n",
    "    x = random.randint(0, img.shape[1] - width)\n",
    "    y = random.randint(0, img.shape[0] - height)\n",
    "    img = img[y:y+height, x:x+width]\n",
    "    mask = mask[y:y+height, x:x+width]\n",
    "    return img, mask\n",
    "\n",
    "# read in files and masks\n",
    "filenames = sorted(glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataRaw/image_data/*.png'))\n",
    "masknames = sorted(glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/dilate_merge_final/*.png'))\n",
    "\n",
    "np.random.seed(1212)\n",
    "for f in filenames:\n",
    "        for m in masknames:\n",
    "            img = cv2.imread(f)\n",
    "            mask = cv2.imread(m,0)\n",
    "\n",
    "            if (m[95:101] == f[81:87]):\n",
    "                crop_img1, crop_mask1 = randomCrop(img, mask, 350, 350)\n",
    "\n",
    "                # prepare rotation matrices\n",
    "                rows, cols = crop_mask1.shape\n",
    "                M90 = cv2.getRotationMatrix2D((cols/2,rows/2),90,1)\n",
    "                M180 = cv2.getRotationMatrix2D((cols/2,rows/2),180,1)\n",
    "                M270 = cv2.getRotationMatrix2D((cols/2,rows/2),270,1)\n",
    "                \n",
    "                # rotate cropped images and masks\n",
    "                # 90 degree rotation\n",
    "                crop_img2, crop_mask2 = randomCrop(img, mask, 350, 350)\n",
    "                crop_rot_img2 = cv2.warpAffine(crop_img2, M90, (cols,rows))\n",
    "                crop_rot_mask2 = cv2.warpAffine(crop_mask2, M90, (cols,rows))\n",
    "\n",
    "                #180 degree rotation\n",
    "                crop_img3, crop_mask3 = randomCrop(img, mask, 350, 350)\n",
    "                crop_rot_img3 = cv2.warpAffine(crop_img3, M180, (cols,rows))\n",
    "                crop_rot_mask3 = cv2.warpAffine(crop_mask3, M180, (cols,rows))\n",
    "\n",
    "                # 270 degree rotation\n",
    "                crop_img4, crop_mask4 = randomCrop(img, mask, 350, 350)\n",
    "                crop_rot_img4 = cv2.warpAffine(crop_img4, M270, (cols,rows))\n",
    "                crop_rot_mask4 = cv2.warpAffine(crop_mask4, M270, (cols,rows))\n",
    "\n",
    "                \n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_images/crop' + f[84:87] + '1.png', crop_img1)\n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_masks/crop' + f[84:87] + '1_mask.png', crop_mask1)\n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_images/crop' + f[84:87] + '2.png', crop_rot_img2)\n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_masks/crop' + f[84:87] + '2_mask.png', crop_rot_mask2)\n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_images/crop' + f[84:87] + '3.png', crop_rot_img3)\n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_masks/crop' + f[84:87] + '3_mask.png', crop_rot_mask3)\n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_images/crop' + f[84:87] + '4.png', crop_rot_img4)\n",
    "                cv2.imwrite('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/crop_masks/crop' + f[84:87] + '4_mask.png', crop_rot_mask4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine weights for weighted cross entropy\n",
    "label_train = np.array([cv2.imread(file,0) for file in glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/train/*_mask.png')])\n",
    "\n",
    "# sum of all labeled pixels\n",
    "np.sum(label_train)/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of all labeled cells\n",
    "(np.sum(label_train)/255)/(60*350*350) # about 6%\n",
    "\n",
    "# weight given to foreground class\n",
    "1/((np.sum(label_train)/255)/(60*350*350))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train TensorFlow Unet (Model 1)\n",
    "# verification batch size = 4, dropout = 0.75\n",
    "# set seed\n",
    "np.random.seed(1212)\n",
    "\n",
    "# set up data and annotation masks\n",
    "# channels = 3, n_class = 2\n",
    "data_provider = image_util.ImageDataProvider(search_path = '/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/train/*.png',\n",
    "                                             data_suffix = '.png', \n",
    "                                             mask_suffix = '_mask.png')\n",
    "net = unet.Unet(channels=data_provider.channels, n_class=data_provider.n_class, \n",
    "                layers=3, features_root=32, cost = 'cross_entropy', \n",
    "                cost_kwargs = {'class_weight': [0.0625, 0.9375]})\n",
    "trainer = unet.Trainer(net, optimizer = \"adam\",\n",
    "                       opt_kwargs = dict(learning_rate = 0.0001))\n",
    "path = trainer.train(data_provider, \"/Users/piper/unet_train\", \n",
    "                     training_iters=20, epochs=100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train TensorFlow Unet (Model 2)\n",
    "# verification batch size = 4, dropout = 0.9\n",
    "\n",
    "# set seed\n",
    "np.random.seed(1212)\n",
    "\n",
    "# set up data and annotation masks\n",
    "# channels = 3, n_class = 2\n",
    "data_provider = image_util.ImageDataProvider(search_path = '/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/train/*.png',\n",
    "                                             data_suffix = '.png', \n",
    "                                             mask_suffix = '_mask.png')\n",
    "net = unet.Unet(channels=data_provider.channels, n_class=data_provider.n_class, \n",
    "                layers=3, features_root=32, cost = 'cross_entropy', \n",
    "                cost_kwargs = {'class_weight': [0.0625, 0.9375]})\n",
    "trainer = unet.Trainer(net, optimizer = \"adam\", \n",
    "                       opt_kwargs = dict(learning_rate = 0.0001))\n",
    "path = trainer.train(data_provider, \"/Users/piper/unet_train\", dropout = 0.9, \n",
    "                     training_iters=20, epochs=100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train TensorFlow Unet (Model 3)\n",
    "# verification batch size = 8, dropout = 0.75\n",
    "# set seed\n",
    "np.random.seed(1212)\n",
    "\n",
    "# set up data and annotation masks\n",
    "# channels = 3, n_class = 2\n",
    "data_provider = image_util.ImageDataProvider(search_path = '/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/train/*.png',\n",
    "                                             data_suffix = '.png', \n",
    "                                             mask_suffix = '_mask.png')\n",
    "net = unet.Unet(channels=data_provider.channels, n_class=data_provider.n_class, \n",
    "                layers=3, features_root=32, cost = 'cross_entropy', \n",
    "                cost_kwargs = {'class_weight': [0.0625, 0.9375]})\n",
    "trainer = unet.Trainer(net, optimizer = \"adam\", verification_batch_size = 8, \n",
    "                       opt_kwargs = dict(learning_rate = 0.0001))\n",
    "path = trainer.train(data_provider, \"/Users/piper/unet_train\", \n",
    "                     training_iters=20, epochs=100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train TensorFlow Unet (Model 4)\n",
    "# verification batch size = 8, dropout = 0.9\n",
    "# set seed\n",
    "np.random.seed(1212)\n",
    "\n",
    "# set up data and annotation masks\n",
    "# channels = 3, n_class = 2\n",
    "data_provider = image_util.ImageDataProvider(search_path = '/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/train/*.png',\n",
    "                                             data_suffix = '.png', \n",
    "                                             mask_suffix = '_mask.png')\n",
    "net = unet.Unet(channels=data_provider.channels, n_class=data_provider.n_class, \n",
    "                layers=3, features_root=32, cost = 'cross_entropy', \n",
    "                cost_kwargs = {'class_weight': [0.0625, 0.9375]})\n",
    "trainer = unet.Trainer(net, optimizer = \"adam\", verification_batch_size = 8, \n",
    "                       opt_kwargs = dict(learning_rate = 0.0001))\n",
    "path = trainer.train(data_provider, \"/Users/piper/unet_train\", dropout = 0.9, \n",
    "                     training_iters=20, epochs=100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply model to test data and predict classes\n",
    "# results shown from model 1 only\n",
    "# set seed\n",
    "np.random.seed(1212)\n",
    "data_test_provider = image_util.ImageDataProvider(search_path = '/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataProcessed/test/*.png', data_suffix = '.png', mask_suffix = '_mask.png')\n",
    "data_test, label_test = data_test_provider(15)\n",
    "\n",
    "# predict classes\n",
    "pred = net.predict('/Users/piper/Unet_Models/Model3/unet_train', data_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of predictions\n",
    "np.shape(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum predicted value for foreground class\n",
    "np.max(pred[:,:,:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop test annotation masks to match predictions\n",
    "pred_final = pred[:,:,:,1]\n",
    "label_test_final = util.crop_to_shape(label_test, pred.shape)\n",
    "label_test_final = label_test_final[:,:,:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that predictions and labels are same shape\n",
    "np.shape(pred_final) == np.shape(label_test_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the predictions\n",
    "for i in range(0,15):\n",
    "    for j in range(0,460):\n",
    "        for k in range(0, 460):\n",
    "            if pred_final[i, j, k] > 0.5:\n",
    "                pred_final[i, j, k] = 1\n",
    "            else:\n",
    "                pred_final[i, j, k] = 0\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate relevant metrics\n",
    "# reshape 3D arrays into 1D array\n",
    "pred_final_1d = pred_final.reshape(-1)\n",
    "label_test_final_1d = label_test_final.reshape(-1)\n",
    "\n",
    "# accuracy\n",
    "acc = sklearn.metrics.accuracy_score(label_test_final_1d, pred_final_1d)\n",
    "acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "prec = sklearn.metrics.precision_score(label_test_final_1d, pred_final_1d)\n",
    "prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "recall = sklearn.metrics.recall_score(label_test_final_1d, pred_final_1d)\n",
    "recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score\n",
    "f1_score = sklearn.metrics.f1_score(label_test_final_1d, pred_final_1d)\n",
    "f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some predictions\n",
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize = (12,5))\n",
    "ax[0].imshow(data_test[0,...,0], aspect=\"auto\", cmap = 'gray')\n",
    "ax[1].imshow(label_test[0,...,1], aspect=\"auto\", cmap = 'gray')\n",
    "mask = pred[0,...,1] > 0.5\n",
    "ax[2].imshow(mask, aspect=\"auto\", cmap = 'gray')\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Prediction\")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize = (12,5))\n",
    "ax[0].imshow(data_test[2,...,0], aspect=\"auto\", cmap = 'gray')\n",
    "ax[1].imshow(label_test[2,...,1], aspect=\"auto\", cmap = 'gray')\n",
    "mask = pred[2,...,1] > 0.5\n",
    "ax[2].imshow(mask, aspect=\"auto\", cmap = 'gray')\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Prediction\")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize = (12,5))\n",
    "ax[0].imshow(data_test[5,...,0], aspect=\"auto\", cmap = 'gray')\n",
    "ax[1].imshow(label_test[5,...,1], aspect=\"auto\", cmap = 'gray')\n",
    "mask = pred[5,...,1] > 0.5\n",
    "ax[2].imshow(mask, aspect=\"auto\", cmap = 'gray')\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Prediction\")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize = (12,5))\n",
    "ax[0].imshow(data_test[8,...,0], aspect=\"auto\", cmap = 'gray')\n",
    "ax[1].imshow(label_test[8,...,1], aspect=\"auto\", cmap = 'gray')\n",
    "mask = pred[8,...,1] > 0.5\n",
    "ax[2].imshow(mask, aspect=\"auto\", cmap = 'gray')\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Prediction\")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize = (12,5))\n",
    "ax[0].imshow(data_test[11,...,0], aspect=\"auto\", cmap = 'gray')\n",
    "ax[1].imshow(label_test[11,...,1], aspect=\"auto\", cmap = 'gray')\n",
    "mask = pred[11,...,1] > 0.5\n",
    "ax[2].imshow(mask, aspect=\"auto\", cmap = 'gray')\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Prediction\")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image as example of image and labels\n",
    "# read in one image for example (img_068)\n",
    "img = cv2.imread('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataRaw/image_data/img068.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# read in corresponding annotation file\n",
    "mat = scipy.io.loadmat('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataRaw/annotation_matfiles/img068_annotations.mat')\n",
    "labs = mat['Labels'].reshape(1,-1,1)\n",
    "pos = np.dstack(mat['Positions'])\n",
    "\n",
    "# create variables of interest\n",
    "mat = np.concatenate((labs, pos), axis = -1)\n",
    "mat_labs = np.uint16(mat[:,:,0]).reshape(-1,1)\n",
    "mat_x = np.uint16(mat[:,:,1]).reshape(-1,1)\n",
    "mat_y = np.uint16(mat[:,:,2]).reshape(-1,1)\n",
    "\n",
    "# create Pandas data frame\n",
    "mat = pd.DataFrame(data=np.column_stack((mat_labs, mat_x, mat_y)), \n",
    "                   columns=['Labels','X','Y'])\n",
    "\n",
    "# show image with labeled cells\n",
    "classes = ['','Y','Z','X']\n",
    "unique = np.unique(classes)\n",
    "colors = {1:'blue', 2:'forestgreen', 3:'darkorange', 4:'red'}\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(img)\n",
    "ax.scatter(mat['X'], mat['Y'], s = 20, \n",
    "           c = mat['Labels'].apply(lambda x: colors[x]))\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make graph to understand distribution of classes\n",
    "filenames = sorted(glob.glob('/Users/piper/Piper Documents/Biomedical Imaging/Final Project/DataRaw/annotation_matfiles/*.mat'))\n",
    "\n",
    "labs_all = []\n",
    "\n",
    "for f in filenames:\n",
    "    mat_file = scipy.io.loadmat(f)\n",
    "    labs = mat_file['Labels']\n",
    "    labs_all.append(labs)\n",
    "    \n",
    "# Concatenate all data into one DataFrame\n",
    "combine_labs = np.concatenate((labs_all[0:29]), axis=None)\n",
    "labs_data = pd.DataFrame(combine_labs, columns = ['Label'])\n",
    "\n",
    "# change labels \n",
    "change_labels = {'Label': {1:'Epithelial', 2:'Fibroblast', 3:'Inflammatory', 4:'Other'}}\n",
    "labs_data.replace(change_labels, inplace=True)\n",
    "\n",
    "# create histogram showing distribution of cell types\n",
    "pd.value_counts(labs_data['Label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of cells\n",
    "np.shape(labs_data)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {'Label':['Epithelial','Fibroblast','Inflammatory','Other'], 'Frequency':[4043,3280,3251,430]} \n",
    "summary_data = pd.DataFrame(summary)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.bar(summary_data['Label'], summary_data['Frequency'])\n",
    "plt.xlabel('Nuclei Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
